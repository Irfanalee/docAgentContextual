# Contextual Retrieval System

A Python implementation of Anthropic's Contextual Retrieval approach for improved document search and retrieval.

## ğŸ“š Overview

This project implements the **Contextual Retrieval** technique described in [Anthropic's Engineering Blog](https://anthropic.com/news/contextual-retrieval), achieving up to **67% improvement** in retrieval accuracy through contextual embeddings and hybrid search.

## ğŸ¯ Key Innovation

Traditional RAG systems chunk documents and embed them directly. This loses context. Our approach adds contextual descriptions to each chunk before embedding, dramatically improving retrieval accuracy.

### Traditional vs Contextual Retrieval

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRADITIONAL RAG                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Document â†’ Chunk â†’ Embed â†’ Store                          â”‚
â”‚                                                             â”‚
â”‚  Chunk: "Revenue grew 25% to $2.3M"                        â”‚
â”‚  âŒ Missing: Which company? Which quarter?                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONTEXTUAL RETRIEVAL (This Implementation)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Document â†’ Chunk â†’ Add Context â†’ Embed â†’ Store            â”‚
â”‚                      â†“                                      â”‚
â”‚                   Claude API                                â”‚
â”‚                                                             â”‚
â”‚  Context: "This chunk is from ACME Corp's Q3 2024          â”‚
â”‚           financial report, discussing revenue growth"      â”‚
â”‚                                                             â”‚
â”‚  Chunk: "Revenue grew 25% to $2.3M"                        â”‚
â”‚  âœ… Now searchable with full context!                      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMPLEMENTED (Phase 1)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. Document Loader                                              â”‚
â”‚     â””â”€> Load PDF files â†’ Extract text                           â”‚
â”‚                                                                  â”‚
â”‚  2. Chunker                                                      â”‚
â”‚     â””â”€> Split text â†’ 800 token chunks with 200 overlap          â”‚
â”‚                                                                  â”‚
â”‚  3. Contextualizer â­ (Key Innovation)                           â”‚
â”‚     â””â”€> Claude API â†’ Generate context for each chunk            â”‚
â”‚                                                                  â”‚
â”‚  4. Embedder                                                     â”‚
â”‚     â””â”€> Sentence Transformers â†’ Create vector embeddings        â”‚
â”‚     â””â”€> Generate BOTH:                                          â”‚
â”‚         â€¢ Standard embedding (chunk only)                        â”‚
â”‚         â€¢ Contextual embedding (context + chunk)                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TODO (Phase 2)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  5. Vector Store (Qdrant)                                        â”‚
â”‚  6. BM25 Index (Lexical Search)                                  â”‚
â”‚  7. Hybrid Retrieval (Vector + BM25)                             â”‚
â”‚  8. Reranking                                                    â”‚
â”‚  9. End-to-End Pipeline                                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Flow

```
INPUT: document.pdf
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Document Loaderâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ Full text
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Chunker     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ List of chunks
             â”‚ [{chunk_text, chunk_id, ...}, ...]
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Contextualizer â”‚â—„â”€â”€â”€ Claude API (Haiku)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ Chunks with context
             â”‚ [{chunk_text, context, ...}, ...]
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Embedder    â”‚â—„â”€â”€â”€ Sentence Transformer
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ Enriched chunks
             â”‚ [{chunk_text, context,
             â”‚   embedding, contextual_embedding}, ...]
             â–¼
         OUTPUT
```

## ğŸ“ Project Structure

```
docagentContextual/
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env                      # API keys (not in git)
â”œâ”€â”€ .env.example              # Example environment file
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_loader.py    # âœ… PDF text extraction
â”‚   â”œâ”€â”€ chunker.py            # âœ… Token-based chunking
â”‚   â”œâ”€â”€ contextualizer.py     # âœ… Claude API integration
â”‚   â”œâ”€â”€ embedder.py           # âœ… Vector embeddings
â”‚   â”œâ”€â”€ vector_store.py       # â³ TODO: Qdrant integration
â”‚   â”œâ”€â”€ bm25_index.py         # â³ TODO: Lexical search
â”‚   â”œâ”€â”€ retriever.py          # â³ TODO: Hybrid retrieval
â”‚   â””â”€â”€ reranker.py           # â³ TODO: Result reranking
â”‚
â”œâ”€â”€ tests/                    # Test scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_chunker.py       # Test chunking logic
â”‚   â”œâ”€â”€ test_contextualizer.py# Test Claude API
â”‚   â””â”€â”€ test_embedder.py      # Test embeddings
â”‚
â””â”€â”€ data/                     # Document storage
    â””â”€â”€ reference.docx        # Sample document
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
cd docagentContextual

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env and add your ANTHROPIC_API_KEY
```

### 2. Configuration

Edit `config.py` or set environment variables:

```python
# API Configuration
ANTHROPIC_API_KEY = "your-key-here"

# Chunking Settings
chunk_size = 800          # Tokens per chunk
chunk_overlap = 200       # Overlap between chunks

# Embedding Model
EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"
EMBEDDING_DIMENSION = 384

# Claude Model
CLAUDE_MODEL = "claude-3-5-haiku-20241022"
```

### 3. Run Tests

```bash
# Test individual components
python tests/test_chunker.py
python tests/test_contextualizer.py
python tests/test_embedder.py
```

## ğŸ’¡ Usage Example

```python
from src.document_loader import load_document
from src.chunker import chunk_text
from src.contextualizer import add_context_to_chunk
from src.embedder import Embedder

# 1. Load document
text = load_document("data/mydocument.pdf")

# 2. Create chunks
chunks = chunk_text(text, chunk_size_tokens=800, chunk_overlap=200)

# 3. Add context to each chunk
for chunk in chunks:
    chunk = add_context_to_chunk(chunk, text)

# 4. Generate embeddings
embedder = Embedder()
enriched_chunks = embedder.embed_chunks(chunks)

# Each chunk now has:
# - chunk_text: Original text
# - context: Contextual description
# - embedding: Standard embedding
# - contextual_embedding: Context + text embedding
```

## ğŸ“ˆ Performance Improvements

Based on Anthropic's research:

| Technique | Improvement |
|-----------|------------|
| Contextual Embeddings | **+35%** |
| Contextual BM25 | **+49%** (combined) |
| With Reranking | **+67%** (total) |

## ğŸ”§ Technologies Used

- **Python 3.10+**
- **Anthropic Claude API** - Context generation (Haiku model)
- **Sentence Transformers** - Text embeddings (all-MiniLM-L6-v2)
- **tiktoken** - Token counting
- **PyPDF2** - PDF parsing
- **Qdrant** - Vector database (coming soon)
- **rank-bm25** - Lexical search (coming soon)

## ğŸ“ Module Descriptions

### âœ… Implemented

#### 1. Document Loader (`src/document_loader.py`)
- Loads PDF documents
- Extracts text content
- Handles multiple document formats

#### 2. Chunker (`src/chunker.py`)
- Splits documents into manageable chunks
- Uses token-based chunking (not character-based)
- Configurable chunk size and overlap
- Preserves context with overlapping chunks

#### 3. Contextualizer (`src/contextualizer.py`) â­
- **Core innovation of the system**
- Uses Claude API to generate contextual descriptions
- Adds situational context to each chunk
- Example: "This chunk discusses Q3 revenue in ACME Corp's financial report"

#### 4. Embedder (`src/embedder.py`)
- Converts text to vector embeddings
- Uses Sentence Transformers (all-MiniLM-L6-v2)
- Generates two embeddings per chunk:
  - Standard embedding (baseline)
  - Contextual embedding (with added context)

### â³ TODO (Phase 2)

#### 5. Vector Store (`src/vector_store.py`)
- Qdrant integration
- Store and index embeddings
- Vector similarity search

#### 6. BM25 Index (`src/bm25_index.py`)
- Lexical search index
- Keyword-based retrieval
- Complement to vector search

#### 7. Hybrid Retriever (`src/retriever.py`)
- Combine vector + BM25 results
- Merge and deduplicate candidates

#### 8. Reranker (`src/reranker.py`)
- Score and rank final results
- Return top-N most relevant chunks

## ğŸ“ Learning Resources

- [Anthropic's Contextual Retrieval Blog Post](https://anthropic.com/news/contextual-retrieval)
- [Sentence Transformers Documentation](https://www.sbert.net/)
- [Qdrant Vector Database](https://qdrant.tech/)

## ğŸ¤ Contributing

This is a learning project! Feel free to:
- Add new features
- Improve existing code
- Add tests
- Enhance documentation

## ğŸ“„ License

MIT License - Feel free to use for learning and development

## ğŸ™ Acknowledgments

- Anthropic for the Contextual Retrieval technique
- Sentence Transformers team for the embedding models
- OpenAI for tiktoken tokenization

---

**Status**: Phase 1 Complete (4/9 modules) âœ…  
**Next Up**: Qdrant Vector Store Integration
